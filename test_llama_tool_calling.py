#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç tool calling —Å llama3.2:3b-instruct
"""

import asyncio
import json
from interactive_chat import OllamaIntegration
from test_client import MCPTestClient


async def test_llama_tool_calling():
    """–¢–µ—Å—Ç llama3.2 —Å tool calling"""
    print("üß™ === –¢–ï–°–¢ LLAMA3.2 TOOL CALLING ===")
    print()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    mcp_client = MCPTestClient(["python3", "mcp_server.py"])
    ollama = OllamaIntegration()  # –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç llama3.2:3b-instruct-q5_K_M
    
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {ollama.model}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Ollama
    if not ollama.check_ollama_availability():
        print("‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
        return
    
    print("‚úÖ Ollama –¥–æ—Å—Ç—É–ø–µ–Ω")
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º MCP —Å–µ—Ä–≤–µ—Ä
        await mcp_client.start_server()
        await mcp_client.initialize()
        
        # –ü–æ–ª—É—á–∞–µ–º MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        mcp_tools = await mcp_client.list_tools()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç Ollama
        ollama_tools = []
        for tool in mcp_tools:
            ollama_tool = {
                "type": "function", 
                "function": {
                    "name": tool["name"],
                    "description": tool["description"],
                    "parameters": tool["inputSchema"]
                }
            }
            ollama_tools.append(ollama_tool)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(ollama_tools)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
        print()
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
        question = "–ü–æ–∫–∞–∂–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–ª–æ—Ç—ã"
        print(f"üìù –¢–ï–°–¢: {question}")
        print("-" * 50)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = [
            {
                "role": "system",
                "content": """You are a helpful assistant. You have access to tools. When user asks for time slots, use get_available_slots tool. Always use tools when needed."""
            },
            {
                "role": "user", 
                "content": question
            }
        ]
        
        print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å...")
        
        # –ó–∞–ø—Ä–æ—Å –≤ Ollama
        response = ollama.chat_with_tools(messages, ollama_tools)
        
        if "error" in response:
            print(f"‚ùå –û—à–∏–±–∫–∞: {response['error']}")
            return
            
        assistant_message = response["message"]
        print(f"üì§ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º tool calls
        if assistant_message.get("tool_calls"):
            tool_calls = assistant_message["tool_calls"]
            print(f"üéâ –£–°–ü–ï–•! –ú–æ–¥–µ–ª—å –≤—ã–∑–≤–∞–ª–∞ {len(tool_calls)} –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤:")
            
            for tool_call in tool_calls:
                function = tool_call["function"]
                print(f"   üìû {function['name']}({function['arguments']})")
                
        else:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –≤—ã–∑–≤–∞–ª–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã")
            content = assistant_message.get("content", "")
            print(f"üí¨ –û—Ç–≤–µ—Ç: {content[:200]}...")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        await mcp_client.stop_server()


if __name__ == "__main__":
    asyncio.run(test_llama_tool_calling()) 